{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "0peLsvcj7PD7"
      },
      "outputs": [],
      "source": [
        "# Required libraries\n",
        "from random import randint, seed\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "BEO04IzUVSzb"
      },
      "outputs": [],
      "source": [
        "# Implement powersets\n",
        "from itertools import chain, combinations\n",
        "\n",
        "def powerset(iterable):\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "tD1okDUx6Id5"
      },
      "outputs": [],
      "source": [
        "class Adaline:\n",
        "\tdef __init__(self, n, rate = 0.2, thresh = 0.5, final = False):\n",
        "\t\tself.countOfNeurons = n+1\n",
        "\t\tself.learningRate = rate\n",
        "\t\tself.thresh = thresh\n",
        "\t\tself.weights = np.random.random((1,(n+1)))[0]\n",
        "  \n",
        "\t\tif final == True:\n",
        "\t\t\tself.weights = np.random.random((1,(n+1)))[0]\n",
        "\t\t\t\n",
        "\tdef activation(self, x):\n",
        "\t\tif x > self.thresh:\n",
        "\t\t\treturn 1\n",
        "\t\t\t\t\n",
        "\t\telse:\n",
        "\t\t\treturn 0\n",
        "\t\t\t\t\n",
        "\tdef _update(self, x, d):\n",
        "\t\tx = np.pad(x, (1, 0), constant_values = 1)\n",
        "\n",
        "\t\t# Forward pass\n",
        "\t\tz = np.dot(x, self.weights)\n",
        "\t\tz = self.activation(z)\n",
        "\t\t\n",
        "\t\td = d - z\n",
        "\t\tchanges = x*d*self.learningRate\n",
        "\n",
        "\t\treturn changes\n",
        "\n",
        "\tdef fit(self, x, d, info = False):\n",
        "\t\tflag = True\n",
        "\t\t\t\n",
        "\t\t# If any weights are updates, recalculate for all samples\n",
        "\t\twhile (flag):\n",
        "\t\t\tflag = False\n",
        "\t\t\tchanges = [0]*self.countOfNeurons\n",
        "\t\t\t\t\n",
        "\t\t\tfor i in range(len(x)):\n",
        "\n",
        "\t\t\t\t# Calculate the required changes\n",
        "\t\t\t\tif (self.predict(x[i])[1] != d[i]):\n",
        "\t\t\t\t\tflag = True\n",
        "\t\t\t\t\tchanges = self._update(x[i], d[i])\n",
        "\t\t\t\t\tself.weights += changes\n",
        "\n",
        "\t\tif not info :\n",
        "\t\t\treturn\n",
        "\t\t\t\n",
        "\t\t# 100% convergence\n",
        "\t\tprint(\"Training Complete\")\n",
        "\t\tprint(self.weights)\n",
        "   \n",
        "\t\treturn\n",
        "\n",
        "\tdef predict(self, x):\n",
        "\t\t\n",
        "\t\tx = np.pad(x, (1, 0), constant_values = 1)\n",
        "\t\ta = np.dot(x, self.weights)\n",
        "\t\tz = self.activation(a)\n",
        "\t\t\n",
        "\t\t# Return both affine and binary output\n",
        "\t\treturn a, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "sqPa3RI96ePM"
      },
      "outputs": [],
      "source": [
        "class Madaline:\n",
        "    def __init__(self, n, hid, rate = 0.3, thresh = 0.5):\n",
        "        self.NoOfNeurons = n+1\n",
        "        self.NoOfHiddenNeurons = hid\n",
        "        self.learningRate = rate\n",
        "        self.threshold = thresh\n",
        "        self.nUnits = [Adaline(n, rate, thresh) for i in range(hid)]\n",
        "        self.finalLayer = Adaline(hid, rate, thresh, final = True)\n",
        "\n",
        "        # Print the initial weights\n",
        "        print(\"Initial Weights: \")\n",
        "        for i in range(len(self.nUnits)):\n",
        "            print(self.nUnits[i].weights)\n",
        "        print()\n",
        "        \n",
        "    \n",
        "    def activation(self, x):\n",
        "        if x > self.threshold:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    \n",
        "    def predict(self, s):\n",
        "      hiddenLayerAffines = []\n",
        "      hiddenLayerOutputs = []\n",
        "              \n",
        "      for j in self.nUnits:\n",
        "          prediction = j.predict(s)\n",
        "          hiddenLayerOutputs.append(prediction[1])\n",
        "          hiddenLayerAffines.append(prediction[0])\n",
        "\n",
        "      finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "      return finalLayerOutput\n",
        "\n",
        "    def fit(self, x, d, info=False):\n",
        "        flag = True\n",
        "        mis = 0\n",
        "        max = 200\n",
        "        # max = 1e7\n",
        "        forAll = False\n",
        "        \n",
        "        # Calculate the initial accuracy.\n",
        "        initWeights = []\n",
        "        for i in range(len(self.nUnits)):\n",
        "            initWeights.append(self.nUnits[i].weights)\n",
        "        \n",
        "        prevAccuracy = self.accuracy(x, d, initWeights)\n",
        "        \n",
        "        noLoop = 0\n",
        "\n",
        "        while(flag and noLoop < max):\n",
        "            noLoop += 1\n",
        "            \n",
        "            flag = False\n",
        "            changed = False\n",
        "            \n",
        "            for i in range(len(x)):\n",
        "\n",
        "                if changed == True:\n",
        "                    break\n",
        "                \n",
        "                \n",
        "                hiddenLayerAffines = []\n",
        "                hiddenLayerOutputs = []\n",
        "                for j in self.nUnits:\n",
        "                    prediction = j.predict(x[i])\n",
        "                    hiddenLayerOutputs.append(prediction[1])\n",
        "                    hiddenLayerAffines.append(abs(prediction[0]))\n",
        "               \n",
        "                # Calculate the predicted value\n",
        "                finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "                # Misclassified sample\n",
        "                if (finalLayerOutput != d[i]):\n",
        "                    print(finalLayerAffine)\n",
        "                    print(prevAccuracy)\n",
        "                    \n",
        "                    flag = True\n",
        "                    changed = False\n",
        "\n",
        "                    toUpdateList = [x for _, x in sorted(zip(hiddenLayerAffines, self.nUnits), key = lambda pair: pair[0])]\n",
        "                    toUpdateListIndexes = [x for _, x in sorted(zip(hiddenLayerAffines, list(range(self.NoOfHiddenNeurons))))]\n",
        "                \n",
        "                    flippedHiddenLayerOutputs = hiddenLayerOutputs[:]\n",
        "                        \n",
        "                    for m in range(len(toUpdateList)):\n",
        "                        flippedHiddenLayerOutputs[toUpdateListIndexes[m]] = 1 if hiddenLayerOutputs[toUpdateListIndexes[m]] == 0 else 0\n",
        "                        \n",
        "                        flippedFinalLayerAffine, flippedFinalLayerOutput = self.finalLayer.predict(flippedHiddenLayerOutputs)\n",
        "                        \n",
        "                        # Changed weights\n",
        "                        changes = []\n",
        "                        forUpdate = []\n",
        "                        for p in range(len(self.nUnits)):\n",
        "                            forUpdate.append(self.nUnits[p].weights)\n",
        "\n",
        "                        \n",
        "                        toUpdate = self.nUnits[toUpdateListIndexes[m]]\n",
        "                        changes = toUpdate._update(x[i], flippedHiddenLayerOutputs[toUpdateListIndexes[m]])\n",
        "                        forUpdate[toUpdateListIndexes[m]] = toUpdate.weights + changes\n",
        "                            \n",
        "                        newAcc = self.accuracy(x, d, forUpdate)\n",
        "                        \n",
        "                        if (newAcc > prevAccuracy):\n",
        "                            prevAccuracy = newAcc\n",
        "                            \n",
        "\n",
        "                            # Update the actual weights if the update is correct\n",
        "                            toUpdate = self.nUnits[toUpdateListIndexes[m]]\n",
        "                            changes = toUpdate._update(x[i], flippedHiddenLayerOutputs[toUpdateListIndexes[m]])\n",
        "                            toUpdate.weights += changes\n",
        "                            \n",
        "                            changed = True\n",
        "                            break\n",
        "\n",
        "                        # Update all incorrect weights including  the final layer if no neuron is selected.\n",
        "                        if (m == len(toUpdateList) - 1):\n",
        "                            whichToUpdate = []\n",
        "\n",
        "                            for j in range(len(self.nUnits)):\n",
        "                                alternative = flippedHiddenLayerOutputs[toUpdateListIndexes[m]]\n",
        "                                new_activation = self.activation(finalLayerAffine - hiddenLayerAffines[j] + alternative)\n",
        "                                new_z = self.activation(new_activation)\n",
        "                                if new_z == self.predict(x[i]):\n",
        "                                    whichToUpdate.append(j)\n",
        "                                    self.nUnits[j].fit([x[i]], [d[i]])\n",
        "                                \n",
        "                            self.finalLayer.fit([hiddenLayerOutputs], [d[i]])\n",
        "                            changed = True\n",
        "                            break;\n",
        "\n",
        "                        \n",
        "        if not info:\n",
        "            return\n",
        "\n",
        "        # Print the information\n",
        "        print(\"Training Complete\")\n",
        "        print(\"Model Converged\")\n",
        "        print(prevAccuracy)\n",
        "\n",
        "        print(\"Final Weights\")\n",
        "        for i in range(len(self.nUnits)):\n",
        "            print(self.nUnits[i].weights)\n",
        "        print()\n",
        "        \n",
        "\n",
        "\n",
        "        return\n",
        "\n",
        "  \n",
        "    def accuracy(self, x, d, newWs):\n",
        "\n",
        "        accuracy = 0\n",
        "\n",
        "        for i in range(len(x)):\n",
        "\n",
        "            hiddenLayerAffines = []\n",
        "            hiddenLayerOutputs = []\n",
        "            \n",
        "            for j in range(len(self.nUnits)):\n",
        "\n",
        "                x2 = np.pad(x[i], (1, 0), constant_values = 1)\n",
        "\n",
        "                z = np.dot(x2, newWs[j])\n",
        "                z = self.activation(z)\n",
        "                hiddenLayerOutputs.append(z)\n",
        "                \n",
        "            finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "            if (finalLayerOutput == d[i]):\n",
        "                accuracy += 1\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku1NMiSgaSSu"
      },
      "outputs": [],
      "source": [
        "# class Madaline:\n",
        "#     def __init__(self, n, hid, rate = 0.3, thresh = 0.5):\n",
        "#         self.NoOfNeurons = n+1\n",
        "#         self.NoOfHiddenNeurons = hid\n",
        "#         self.learningRate = rate\n",
        "#         self.threshold = thresh\n",
        "#         self.nUnits = [Adaline(n, rate, thresh) for i in range(hid)]\n",
        "#         self.finalLayer = Adaline(hid, rate, thresh, final = True)\n",
        "\n",
        "#         # Print the initial weights\n",
        "#         print(\"Initial Weights: \")\n",
        "#         for i in range(len(self.nUnits)):\n",
        "#             print(self.nUnits[i].weights)\n",
        "#         print()\n",
        "        \n",
        "    \n",
        "#     def activation(self, x):\n",
        "#         if x > self.threshold:\n",
        "#             return 1\n",
        "#         else:\n",
        "#             return 0\n",
        "    \n",
        "#     def predict(self, s):\n",
        "#       hiddenLayerAffines = []\n",
        "#       hiddenLayerOutputs = []\n",
        "              \n",
        "#       for j in self.nUnits:\n",
        "#           prediction = j.predict(s)\n",
        "#           hiddenLayerOutputs.append(prediction[1])\n",
        "#           hiddenLayerAffines.append(prediction[0])\n",
        "\n",
        "#       finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "#       return finalLayerOutput\n",
        "\n",
        "#     def fit(self, x, d, info=False):\n",
        "#         flag = True\n",
        "#         mis = 0\n",
        "#         max = 10000\n",
        "        \n",
        "#         # Calculate the initial accuracy.\n",
        "#         initWeights = []\n",
        "#         for i in range(len(self.nUnits)):\n",
        "#             initWeights.append(self.nUnits[i].weights)\n",
        "        \n",
        "#         prevAccuracy = self.accuracy(x, d, initWeights)\n",
        "#         noLoop = 0\n",
        "\n",
        "#         while(flag):\n",
        "#             noLoop += 1\n",
        "            \n",
        "#             flag = False\n",
        "#             changed = False\n",
        "            \n",
        "#             for i in range(len(x)):\n",
        "\n",
        "#                 if changed == True:\n",
        "#                     break\n",
        "                \n",
        "                \n",
        "#                 hiddenLayerAffines = []\n",
        "#                 hiddenLayerOutputs = []\n",
        "#                 for j in self.nUnits:\n",
        "#                     prediction = j.predict(x[i])\n",
        "#                     hiddenLayerOutputs.append(prediction[1])\n",
        "#                     hiddenLayerAffines.append(abs(prediction[0]))\n",
        "               \n",
        "#                 # Calculate the predicted value\n",
        "#                 finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "#                 # Misclassified sample\n",
        "#                 if (finalLayerOutput != d[i]):\n",
        "                    \n",
        "#                     flag = True\n",
        "#                     changed = False\n",
        "\n",
        "#                     # Make the powerset after sorting it along the affine values\n",
        "#                     toUpdateList = [x for _, x in sorted(zip(hiddenLayerAffines, self.nUnits), key = lambda pair: pair[0])]\n",
        "#                     toUpdateList = list(powerset(toUpdateList))\n",
        "#                     toUpdateListIndexes = [x for _, x in sorted(zip(hiddenLayerAffines, list(range(self.NoOfHiddenNeurons))))]\n",
        "#                     toUpdateListIndexes = list(powerset(toUpdateListIndexes))\n",
        "\n",
        "#                     final = False\n",
        "#                     for k in range(len(toUpdateList)):\n",
        "\n",
        "#                         if (k == len(toUpdateList) - 1 or len(toUpdateList[k]) >= 2):\n",
        "#                             final = True\n",
        "                            \n",
        "#                         # print(k)\n",
        "#                         # Changed outputs\n",
        "#                         flippedHiddenLayerOutputs = hiddenLayerOutputs[:]\n",
        "                        \n",
        "#                         for m in range(len(toUpdateList[k])):\n",
        "#                             flippedHiddenLayerOutputs[toUpdateListIndexes[k][m]] = 1 if hiddenLayerOutputs[toUpdateListIndexes[k][m]] == 0 else 0\n",
        "                        \n",
        "#                         flippedFinalLayerAffine, flippedFinalLayerOutput = self.finalLayer.predict(flippedHiddenLayerOutputs)\n",
        "                        \n",
        "#                         # Changed weights\n",
        "#                         changes = []\n",
        "#                         forUpdate = []\n",
        "#                         for p in range(len(self.nUnits)):\n",
        "#                             forUpdate.append(self.nUnits[p].weights)\n",
        "\n",
        "                        \n",
        "#                         for m in range(len(toUpdateList[k])):\n",
        "#                             toUpdate = self.nUnits[toUpdateListIndexes[k][m]]\n",
        "#                             changes = toUpdate._update(x[i], flippedHiddenLayerOutputs[toUpdateListIndexes[k][m]])\n",
        "#                             forUpdate[toUpdateListIndexes[k][m]] = toUpdate.weights + changes\n",
        "                            \n",
        "#                             #  New accuracy\n",
        "#                         newAcc = self.accuracy(x, d, forUpdate)\n",
        "#                         # print(forUpdate)\n",
        "                        \n",
        "#                         if (newAcc > prevAccuracy or final == True):\n",
        "#                             prevAccuracy = newAcc\n",
        "                            \n",
        "\n",
        "#                             # Update the actual weights if the update is correct\n",
        "#                             for m in range(len(toUpdateList[k])):\n",
        "#                                 toUpdate = self.nUnits[toUpdateListIndexes[k][m]]\n",
        "#                                 changes = toUpdate._update(x[i], flippedHiddenLayerOutputs[toUpdateListIndexes[k][m]])\n",
        "#                                 toUpdate.weights += changes\n",
        "                            \n",
        "#                             changed = True\n",
        "#                             break\n",
        "                        \n",
        "#         if not info:\n",
        "#             return\n",
        "\n",
        "#         # Print the information\n",
        "#         print(\"Training Complete\")\n",
        "#         print(\"Model Converged\")\n",
        "#         print(prevAccuracy)\n",
        "\n",
        "#         print(\"Final Weights\")\n",
        "#         for i in range(len(self.nUnits)):\n",
        "#             print(self.nUnits[i].weights)\n",
        "#         print()\n",
        "        \n",
        "\n",
        "\n",
        "#         return\n",
        "\n",
        "  \n",
        "#     def accuracy(self, x, d, newWs):\n",
        "\n",
        "#         accuracy = 0\n",
        "\n",
        "#         for i in range(len(x)):\n",
        "\n",
        "#             hiddenLayerAffines = []\n",
        "#             hiddenLayerOutputs = []\n",
        "            \n",
        "#             for j in range(len(self.nUnits)):\n",
        "\n",
        "#                 x2 = np.pad(x[i], (1, 0), constant_values = 1)\n",
        "\n",
        "#                 z = np.dot(x2, newWs[j])\n",
        "#                 z = self.activation(z)\n",
        "#                 hiddenLayerOutputs.append(z)\n",
        "                \n",
        "#             finalLayerAffine, finalLayerOutput = self.finalLayer.predict(hiddenLayerOutputs)\n",
        "\n",
        "#             if (finalLayerOutput == d[i]):\n",
        "#                 accuracy += 1\n",
        "\n",
        "#         return accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fz4tGToZ7BFQ",
        "outputId": "e24344d8-203f-4b1c-8e2d-f45b57300a78"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The training data\n",
        "\n",
        "# Function for image\n",
        "def function(x1, x2):\n",
        "    if (x1 < 0 or x1 > 10 or x2 < 0 or x2 > 10):\n",
        "        return 0\n",
        "    if (x1 >= 4 and x1 <= 6):\n",
        "        if (x2 >= 0 and x2 <= 2) or (x2 >= 4 and x2 <= 6) or (x2 >= 8 and x2 <= 10):\n",
        "            return 1\n",
        "    if (x1 >= 0 and x1 <= 2)  or (x1 >= 8 and x1 <= 10):\n",
        "        if (x2 >= 4 and x2 <= 6):\n",
        "            return 1 \n",
        "    return 0\n",
        "\n",
        "# Making teh data\n",
        "def makeData():\n",
        "    train = []\n",
        "    for x1 in range(-1, 12):\n",
        "        for x2 in range(-1, 12):\n",
        "            train.append([x1/10, x2/10, function(x1, x2)])\n",
        "\n",
        "    return train\n",
        "\n",
        "# Plotting the data\n",
        "def plotData(train):\n",
        "    red_x1 = []\n",
        "    red_x2 = []\n",
        "    white_x1 = []\n",
        "    white_x2 = []\n",
        "\n",
        "    for pt in train:\n",
        "        if (pt[2] == 1):\n",
        "            red_x1.append(pt[0]*10)\n",
        "            red_x2.append(pt[1]*10)\n",
        "        else:\n",
        "            white_x1.append(pt[0]*10)\n",
        "            white_x2.append(pt[1]*10)\n",
        "\n",
        "    plt.scatter(red_x1, red_x2, c = 'r', alpha = 1)\n",
        "    plt.scatter(white_x1, white_x2, c = 'g', alpha = 0.05)\n",
        "    plt.show()\n",
        "\n",
        "train = makeData()\n",
        "plotData(train)\n",
        "\n",
        "train = np.array(train)\n",
        "trainX = train.T[0:2]\n",
        "trainX = trainX.T\n",
        "\n",
        "trainy = train.T[-1]\n",
        "trainy = trainy.T\n",
        "\n",
        "def printAccuracy(ypred, ytrue):\n",
        "    return np.sum(ypred == ytrue)/len(ypred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "lhmKFTtn6f65"
      },
      "outputs": [],
      "source": [
        "# Training the algorithm for n = 2 and h = 21\n",
        "seed(0)\n",
        "n = 2\n",
        "h = 21\n",
        "s = trainX\n",
        "z = trainy\n",
        "np.random.shuffle(s)\n",
        "np.random.shuffle(z)\n",
        "net = Madaline(n, h, 0.01, 0.5)\n",
        "net.fit(s, z, True)\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "for i in s: \n",
        "    y_pred.append(net.predict(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "DtNj7fDhomqR"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "weights = []\n",
        "for i in range(len(net.nUnits)):\n",
        "    weights.append(net.nUnits[i].weights)\n",
        "\n",
        "fl = net.finalLayer.weights\n",
        "np.save('q2_21_w.npy', np.array(weights))\n",
        "np.save('q2_21_fl.npy', np.array(fl))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Wz9syppStH0O"
      },
      "outputs": [],
      "source": [
        "ws = np.load('q2_21_w.npy')\n",
        "f = np.load('q2_21_fl.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "3k4i0ILQvB8K"
      },
      "outputs": [],
      "source": [
        "accuracy = 0\n",
        "for i in range(len(s)):\n",
        "\n",
        "    hiddenLayerOutputs = []\n",
        "            \n",
        "    for j in range(21):\n",
        "\n",
        "        x2 = np.pad(s[i], (1, 0), constant_values = 1)\n",
        "\n",
        "        l = np.dot(x2, ws[j])\n",
        "        l = 1 if l > 0.5 else 0\n",
        "        hiddenLayerOutputs.append(l)\n",
        "                \n",
        "    x2 = np.pad(hiddenLayerOutputs, (1, 0), constant_values = 1)\n",
        "    finalLayerAffine = np.dot(x2, f)\n",
        "    finalLayerOutput = 1 if finalLayerAffine > 0.5 else 0 \n",
        "\n",
        "    if (finalLayerOutput == z[i]):\n",
        "        accuracy += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaZCw9zvluJH"
      },
      "outputs": [],
      "source": [
        "# Sample model for XOR data, using 2 neurons.\n",
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "d = np.array([0, 1, 1, 0])\n",
        "\n",
        "n = 2\n",
        "h = 2\n",
        "net = Madaline(n, h, 0.01, 0.5)\n",
        "net.fit(x, d, True)\n",
        "\n",
        "for i in x:\n",
        "    print(net.predict(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G266GTGRyVge"
      },
      "outputs": [],
      "source": [
        "# Training the algorithm for n = 2 and h = 2\n",
        "seed(0)\n",
        "n = 2\n",
        "h = 2\n",
        "s = trainX\n",
        "z = trainy\n",
        "np.random.shuffle(s)\n",
        "np.random.shuffle(z)\n",
        "net2 = Madaline(n, h, 0.01, 0.5)\n",
        "net2.fit(s, z, True)\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "for i in s: \n",
        "    y_pred.append(net.predict(i))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DL_A1_Q2_Madaline2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
